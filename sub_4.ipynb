{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 99807,
          "databundleVersionId": 11970628,
          "isSourceIdPinned": false,
          "sourceType": "competition"
        },
        {
          "sourceId": 11930548,
          "sourceType": "datasetVersion",
          "datasetId": 7500669
        },
        {
          "sourceId": 11932238,
          "sourceType": "datasetVersion",
          "datasetId": 7501773
        }
      ],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "sub_4",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saybuuu/test_cases/blob/main/sub_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "82LDs73dDiws"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "21vek_query_classification_path = kagglehub.competition_download('21vek-query-classification')\n",
        "vladislavbukhtoyarov_dataset_path = kagglehub.dataset_download('vladislavbukhtoyarov/dataset')\n",
        "vladislavbukhtoyarov_kaggle_api_key_path = kagglehub.dataset_download('vladislavbukhtoyarov/kaggle-api-key')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "GvAOT3NbDiwv"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T09:24:07.591414Z",
          "iopub.execute_input": "2025-05-25T09:24:07.591911Z",
          "iopub.status.idle": "2025-05-25T09:24:07.90071Z",
          "shell.execute_reply.started": "2025-05-25T09:24:07.591888Z",
          "shell.execute_reply": "2025-05-25T09:24:07.899909Z"
        },
        "id": "fJSCh7NuDiwv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "category_path = \"/kaggle/input/21vek-query-classification/categories.csv\"\n",
        "sample_path   = \"/kaggle/input/21vek-query-classification/sample_submission.csv\"\n",
        "test_path     = \"/kaggle/input/21vek-query-classification/test.csv\"\n",
        "train_path    = \"/kaggle/input/21vek-query-classification/train.csv\""
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-10T17:46:06.809157Z",
          "start_time": "2025-05-10T17:46:06.804175Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T09:24:07.901931Z",
          "iopub.execute_input": "2025-05-25T09:24:07.902325Z",
          "iopub.status.idle": "2025-05-25T09:24:07.905798Z",
          "shell.execute_reply.started": "2025-05-25T09:24:07.90229Z",
          "shell.execute_reply": "2025-05-25T09:24:07.905262Z"
        },
        "id": "ePqg4ehbDiww"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv(test_path)\n",
        "train = pd.read_csv(train_path)\n",
        "del train['ID']\n",
        "sample = pd.read_csv(sample_path)\n",
        "categories = pd.read_csv(category_path)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-10T17:46:07.496521Z",
          "start_time": "2025-05-10T17:46:07.450801Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T09:24:07.906459Z",
          "iopub.execute_input": "2025-05-25T09:24:07.906654Z",
          "iopub.status.idle": "2025-05-25T09:24:07.957027Z",
          "shell.execute_reply.started": "2025-05-25T09:24:07.906638Z",
          "shell.execute_reply": "2025-05-25T09:24:07.956357Z"
        },
        "id": "d76TrTS8Diww"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.isnull().sum())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T09:24:07.958679Z",
          "iopub.execute_input": "2025-05-25T09:24:07.958913Z",
          "iopub.status.idle": "2025-05-25T09:24:07.963901Z",
          "shell.execute_reply.started": "2025-05-25T09:24:07.958898Z",
          "shell.execute_reply": "2025-05-25T09:24:07.963387Z"
        },
        "id": "ijz3w6epDiww"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# categories.info\n",
        "print(len(categories))"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-10T09:05:36.840057Z",
          "start_time": "2025-05-10T09:05:36.826499Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T09:24:07.964554Z",
          "iopub.execute_input": "2025-05-25T09:24:07.96479Z",
          "iopub.status.idle": "2025-05-25T09:24:07.975686Z",
          "shell.execute_reply.started": "2025-05-25T09:24:07.964767Z",
          "shell.execute_reply": "2025-05-25T09:24:07.974893Z"
        },
        "id": "39Bs0YfqDiwx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "used_ids = sorted(train['CategoryID'].unique())\n",
        "print(\"Missing:\", [x for x in range(min(used_ids), max(used_ids)+1) if x not in used_ids])"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-10T09:05:37.65743Z",
          "start_time": "2025-05-10T09:05:37.645175Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T09:24:07.976404Z",
          "iopub.execute_input": "2025-05-25T09:24:07.976573Z",
          "iopub.status.idle": "2025-05-25T09:24:07.993233Z",
          "shell.execute_reply.started": "2025-05-25T09:24:07.976559Z",
          "shell.execute_reply": "2025-05-25T09:24:07.992681Z"
        },
        "id": "aQsEov93Diwx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(categories[categories['CategoryID'] == 62])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T09:24:07.994088Z",
          "iopub.execute_input": "2025-05-25T09:24:07.994323Z",
          "iopub.status.idle": "2025-05-25T09:24:08.010064Z",
          "shell.execute_reply.started": "2025-05-25T09:24:07.994301Z",
          "shell.execute_reply": "2025-05-25T09:24:08.009498Z"
        },
        "id": "m8_pOY37Diwx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "vinyl_products = [\n",
        "    {\"CategoryID\": 62, \"Query\": \"Виниловая пластинка The Beatles - Abbey Road\"},\n",
        "    {\"CategoryID\": 62, \"Query\": \"Винил Pink Floyd - The Dark Side of the Moon\"},\n",
        "    {\"CategoryID\": 62, \"Query\": \"Виниловая пластинка Led Zeppelin - IV\"},\n",
        "    {\"CategoryID\": 62, \"Query\": \"Винил Queen - A Night at the Opera\"},\n",
        "    {\"CategoryID\": 62, \"Query\": \"Виниловая пластинка The Rolling Stones - Sticky Fingers\"},\n",
        "    {\"CategoryID\": 62, \"Query\": \"Пластинка Nirvana\"},\n",
        "    {\"CategoryID\": 62, \"Query\": \"Виниловая пластинка Michael Jackson - Thriller\"},\n",
        "    {\"CategoryID\": 62, \"Query\": \"Виниловая пластинка David Bowie - Heroes\"},\n",
        "    {\"CategoryID\": 62, \"Query\": \"Виниловая пластинка Radiohead - OK Computer\"},\n",
        "    {\"CategoryID\": 62, \"Query\": \"Винил Master of Puppets\"},\n",
        "    {\"CategoryID\": 62, \"Query\": \"Виниловая пластинка The Who - Who's Next\"},\n",
        "    {\"CategoryID\": 62, \"Query\": \"Виниловая пластинка U2 \"},\n",
        "    {\"CategoryID\": 62, \"Query\": \"Red Hot Chili Peppers - Californication\"},\n",
        "    {\"CategoryID\": 62, \"Query\": \"пластинка AC/DC - Back in Black\"},\n",
        "    {\"CategoryID\": 62, \"Query\": \"Виниловая пластинка Pearl Jam - Ten\"},\n",
        "    {\"CategoryID\": 62, \"Query\": \" пластинка Oasis - (What's the Story) Morning Glory?\"},\n",
        "    {\"CategoryID\": 62, \"Query\": \"Виниловая пластинка Guns N' Roses - Appetite for Destruction\"},\n",
        "    {\"CategoryID\": 62, \"Query\": \"пластинка The Doors - The Doors\"},\n",
        "    {\"CategoryID\": 62, \"Query\": \"пластинка Bob Dylan - Highway 61 Revisited\"},\n",
        "    {\"CategoryID\": 62, \"Query\": \"пластинка Simon & Garfunkel - Bridge Over Troubled Water\"},\n",
        "]\n",
        "\n",
        "train = pd.concat([train, pd.DataFrame(vinyl_products)], ignore_index=True)\n",
        "print(len(train))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T09:24:08.010718Z",
          "iopub.execute_input": "2025-05-25T09:24:08.011177Z",
          "iopub.status.idle": "2025-05-25T09:24:08.02593Z",
          "shell.execute_reply.started": "2025-05-25T09:24:08.011152Z",
          "shell.execute_reply": "2025-05-25T09:24:08.025236Z"
        },
        "id": "7Y32oeCVDiwx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "counts = train.groupby('CategoryID').size()\n",
        "counts = counts.sort_values()\n",
        "counts.head(10)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T09:24:08.026915Z",
          "iopub.execute_input": "2025-05-25T09:24:08.027172Z",
          "iopub.status.idle": "2025-05-25T09:24:08.048748Z",
          "shell.execute_reply.started": "2025-05-25T09:24:08.027153Z",
          "shell.execute_reply": "2025-05-25T09:24:08.048175Z"
        },
        "id": "pQbWjxXNDiwy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-10T09:05:36.803644Z",
          "start_time": "2025-05-10T09:05:35.682685Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T09:24:08.050309Z",
          "iopub.execute_input": "2025-05-25T09:24:08.05053Z",
          "iopub.status.idle": "2025-05-25T09:24:08.059682Z",
          "shell.execute_reply.started": "2025-05-25T09:24:08.050516Z",
          "shell.execute_reply": "2025-05-25T09:24:08.058993Z"
        },
        "id": "fco58oFWDiwy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,1, figsize=(10, 5))\n",
        "train.groupby('CategoryID').Query.count().sort_values().plot.bar(x='CategoryID', y='Query')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-10T09:05:37.628422Z",
          "start_time": "2025-05-10T09:05:36.90005Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T09:24:08.060304Z",
          "iopub.execute_input": "2025-05-25T09:24:08.060478Z",
          "iopub.status.idle": "2025-05-25T09:24:08.425996Z",
          "shell.execute_reply.started": "2025-05-25T09:24:08.060465Z",
          "shell.execute_reply": "2025-05-25T09:24:08.425246Z"
        },
        "id": "Q8V-iSFRDiwy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy3"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T09:24:08.427304Z",
          "iopub.execute_input": "2025-05-25T09:24:08.427518Z",
          "iopub.status.idle": "2025-05-25T09:24:11.445098Z",
          "shell.execute_reply.started": "2025-05-25T09:24:08.427501Z",
          "shell.execute_reply": "2025-05-25T09:24:11.444409Z"
        },
        "id": "uLr8YRQaDiwy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T09:24:11.445996Z",
          "iopub.execute_input": "2025-05-25T09:24:11.446192Z",
          "iopub.status.idle": "2025-05-25T09:24:14.396743Z",
          "shell.execute_reply.started": "2025-05-25T09:24:11.44617Z",
          "shell.execute_reply": "2025-05-25T09:24:14.396016Z"
        },
        "id": "OIwY91wDDiwy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from pymorphy3 import MorphAnalyzer\n",
        "import nltk\n",
        "import random\n",
        "from sklearn.utils import resample\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import stopwords\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "import math\n",
        "from googletrans import Translator\n",
        "import time\n",
        "import asyncio"
      ],
      "metadata": {
        "jupyter": {
          "is_executing": true
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T09:24:14.397799Z",
          "iopub.execute_input": "2025-05-25T09:24:14.398225Z",
          "iopub.status.idle": "2025-05-25T09:24:22.640435Z",
          "shell.execute_reply.started": "2025-05-25T09:24:14.398197Z",
          "shell.execute_reply": "2025-05-25T09:24:22.639816Z"
        },
        "id": "jSchwJnTDiwy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.version.cuda)\n",
        "print(torch.cuda.get_device_capability())"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-10T09:05:48.911162Z",
          "start_time": "2025-05-10T09:05:48.905211Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T09:24:22.642882Z",
          "iopub.execute_input": "2025-05-25T09:24:22.643569Z",
          "iopub.status.idle": "2025-05-25T09:24:22.647818Z",
          "shell.execute_reply.started": "2025-05-25T09:24:22.643545Z",
          "shell.execute_reply": "2025-05-25T09:24:22.647208Z"
        },
        "id": "GOKzzTxmDiwz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "categories.rename(columns={'CategoryName': 'Query'}, inplace=True)\n",
        "train = pd.concat([train, categories], ignore_index=True)\n",
        "print(len(train))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T09:24:22.648597Z",
          "iopub.execute_input": "2025-05-25T09:24:22.648853Z",
          "iopub.status.idle": "2025-05-25T09:24:22.665954Z",
          "shell.execute_reply.started": "2025-05-25T09:24:22.648829Z",
          "shell.execute_reply": "2025-05-25T09:24:22.665428Z"
        },
        "id": "NQDJ41kCDiwz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def char_augment(text, prob=0.1):\n",
        "    result = []\n",
        "    for char in text:\n",
        "        if random.random() < prob:\n",
        "            if char.isalpha():\n",
        "                if random.random() > 0.5:\n",
        "                    result.append(char.swapcase())\n",
        "                else:\n",
        "                    key_ru = {'о':'а', 'е':'э', 'ш':'щ', '0':'1'}\n",
        "                    key_en = {'o':'p', 'e':'r', 't':'y', '1':'2'}\n",
        "                    replacement = key_ru.get(char.lower(), key_en.get(char.lower(), char))\n",
        "                    result.append(replacement)\n",
        "            elif char.isdigit():\n",
        "                result.append(str((int(char) + random.randint(0, 2)) % 10))\n",
        "            else:\n",
        "                result.append(char)\n",
        "        else:\n",
        "            result.append(char)\n",
        "    return ''.join(result)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-10T09:05:50.222927200Z",
          "start_time": "2025-05-09T15:11:27.243348Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T09:24:22.66673Z",
          "iopub.execute_input": "2025-05-25T09:24:22.666996Z",
          "iopub.status.idle": "2025-05-25T09:24:22.679842Z",
          "shell.execute_reply.started": "2025-05-25T09:24:22.666951Z",
          "shell.execute_reply": "2025-05-25T09:24:22.679144Z"
        },
        "id": "ppNvc2q5Diwz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-10T09:05:50.226954900Z",
          "start_time": "2025-05-09T15:10:15.420305Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T09:24:22.680528Z",
          "iopub.execute_input": "2025-05-25T09:24:22.680751Z",
          "iopub.status.idle": "2025-05-25T09:24:22.756173Z",
          "shell.execute_reply.started": "2025-05-25T09:24:22.680736Z",
          "shell.execute_reply": "2025-05-25T09:24:22.755542Z"
        },
        "id": "gb7cMYm7Diwz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "morph_ru = MorphAnalyzer()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-10T09:05:50.227959Z",
          "start_time": "2025-05-09T15:10:17.701707Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T09:24:22.756845Z",
          "iopub.execute_input": "2025-05-25T09:24:22.757082Z",
          "iopub.status.idle": "2025-05-25T09:24:23.166571Z",
          "shell.execute_reply.started": "2025-05-25T09:24:22.757057Z",
          "shell.execute_reply": "2025-05-25T09:24:23.165786Z"
        },
        "id": "PQn9xeNsDiwz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def synonym_replacement(text, lang='ru', prob=0.3):\n",
        "    words = text.split()\n",
        "    for i, word in enumerate(words):\n",
        "        if random.random() < prob:\n",
        "            if lang == 'ru':\n",
        "                parsed = morph_ru.parse(word)[0]\n",
        "                if parsed.score > 0.5 and len(parsed.lexeme) > 1:\n",
        "                    words[i] = random.choice(parsed.lexeme).word\n",
        "            else:  # en\n",
        "                syns = wn.synsets(word)\n",
        "                if syns:\n",
        "                    lemmas = [l.name() for syn in syns for l in syn.lemmas()]\n",
        "                    if lemmas:\n",
        "                        words[i] = random.choice(lemmas)\n",
        "    return ' '.join(words)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-10T09:05:50.227959Z",
          "start_time": "2025-05-09T15:12:05.97981Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T09:24:23.16746Z",
          "iopub.execute_input": "2025-05-25T09:24:23.167674Z",
          "iopub.status.idle": "2025-05-25T09:24:23.173051Z",
          "shell.execute_reply.started": "2025-05-25T09:24:23.167658Z",
          "shell.execute_reply": "2025-05-25T09:24:23.17225Z"
        },
        "id": "KvM1c7N0Diwz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-10T09:05:50.230066300Z",
          "start_time": "2025-05-09T15:12:42.041639Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T09:24:23.17384Z",
          "iopub.execute_input": "2025-05-25T09:24:23.174528Z",
          "iopub.status.idle": "2025-05-25T09:24:23.192187Z",
          "shell.execute_reply.started": "2025-05-25T09:24:23.174503Z",
          "shell.execute_reply": "2025-05-25T09:24:23.191536Z"
        },
        "id": "4VTrty_lDiwz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords_ru = set(stopwords.words('russian'))\n",
        "stopwords_en = set(stopwords.words('english'))"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-10T09:05:50.230066300Z",
          "start_time": "2025-05-09T15:12:59.668201Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T09:24:23.192961Z",
          "iopub.execute_input": "2025-05-25T09:24:23.193254Z",
          "iopub.status.idle": "2025-05-25T09:24:23.203994Z",
          "shell.execute_reply.started": "2025-05-25T09:24:23.193234Z",
          "shell.execute_reply": "2025-05-25T09:24:23.203502Z"
        },
        "id": "LsUKKrXgDiwz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_words(text, prob=0.3):\n",
        "    words = text.split()\n",
        "    protected_indices = [\n",
        "        idx for idx, word in enumerate(words) if any(char.isdigit() for char in word)\n",
        "    ]\n",
        "    non_protected_indices = [\n",
        "        idx for idx in range(len(words)) if idx not in protected_indices\n",
        "    ]\n",
        "    for i in non_protected_indices:\n",
        "        if random.random() < prob:\n",
        "            j = random.choice(non_protected_indices)\n",
        "            words[i], words[j] = words[j], words[i]\n",
        "\n",
        "    return ' '.join(words)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-10T09:05:50.230066300Z",
          "start_time": "2025-05-09T15:13:07.565445Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T09:24:23.20467Z",
          "iopub.execute_input": "2025-05-25T09:24:23.204903Z",
          "iopub.status.idle": "2025-05-25T09:24:23.219615Z",
          "shell.execute_reply.started": "2025-05-25T09:24:23.204883Z",
          "shell.execute_reply": "2025-05-25T09:24:23.218966Z"
        },
        "id": "mtyElJ9zDiw0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "async def back_translate(text, src_lang='auto', intermediate_langs=['de', 'fr']):\n",
        "\n",
        "    translator = Translator()\n",
        "\n",
        "    try:\n",
        "        if src_lang == 'auto':\n",
        "            detection = await translator.detect(text)\n",
        "            detected_lang = detection.lang\n",
        "            src_lang = detected_lang if detected_lang in ['en', 'ru'] else 'ru'\n",
        "\n",
        "        intermediate_lang = random.choice(intermediate_langs)\n",
        "\n",
        "        translated_result = await translator.translate(text, dest=intermediate_lang, src=src_lang)\n",
        "        translated_text = translated_result.text\n",
        "\n",
        "        await asyncio.sleep(0.5)\n",
        "\n",
        "        back_translated_result = await translator.translate(\n",
        "            translated_text, dest=src_lang, src=intermediate_lang\n",
        "        )\n",
        "        back_translated_text = back_translated_result.text\n",
        "\n",
        "        return back_translated_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error in back_translate: {e}\")\n",
        "        return text\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T09:24:23.220234Z",
          "iopub.execute_input": "2025-05-25T09:24:23.220444Z",
          "iopub.status.idle": "2025-05-25T09:24:23.233522Z",
          "shell.execute_reply.started": "2025-05-25T09:24:23.220409Z",
          "shell.execute_reply": "2025-05-25T09:24:23.232896Z"
        },
        "id": "rYwtUjenDiw0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "new_rows = []\n",
        "for row in categories.itertuples():\n",
        "    new_query = await back_translate(row.Query)\n",
        "    new_rows.append(\n",
        "        {\n",
        "            'CategoryID': int(row.CategoryID),\n",
        "            'Query': f'{new_query}'\n",
        "        }\n",
        "    )\n",
        "\n",
        "train = pd.concat([train, pd.DataFrame(new_rows)], ignore_index=True)\n",
        "print(len(train))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T09:24:23.234113Z",
          "iopub.execute_input": "2025-05-25T09:24:23.234268Z"
        },
        "id": "BJ-ABeOGDiw0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "counts = train.groupby('CategoryID').size()\n",
        "counts = counts.sort_values()\n",
        "counts.head(10)"
      ],
      "metadata": {
        "trusted": true,
        "id": "VQHgFP-xDiw0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def text_mixing(text1, text2, split_range=(0.3, 0.7)):\n",
        "    words1 = text1.split()\n",
        "    words2 = text2.split()\n",
        "\n",
        "    split_point1 = int(len(words1) * random.uniform(*split_range))\n",
        "    split_point2 = int(len(words2) * random.uniform(*split_range))\n",
        "\n",
        "    mixed_words = words1[:split_point1] + words2[split_point2:]\n",
        "    mixed_text = ' '.join(mixed_words)\n",
        "\n",
        "    return mixed_text"
      ],
      "metadata": {
        "trusted": true,
        "id": "US53Eqg3Diw0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for category_id in counts.index:\n",
        "    new_rows = []\n",
        "\n",
        "    if 2 <= counts[category_id] < 50:\n",
        "        filtered_queries = train[train['CategoryID'] == category_id]\n",
        "        iters = int(30 - counts[category_id])\n",
        "        for row in filtered_queries.itertuples():\n",
        "            queries = filtered_queries[filtered_queries.index != row.Index]['Query'].tolist()\n",
        "            new_query = text_mixing(row.Query, random.choice(queries))\n",
        "            new_rows.append(\n",
        "                {\n",
        "                    'CategoryID': int(row.CategoryID),\n",
        "                    'Query': f'{new_query}'\n",
        "                }\n",
        "            )\n",
        "            iters -=1\n",
        "        if iters == 0:\n",
        "            break\n",
        "\n",
        "        train = pd.concat([train, pd.DataFrame(new_rows)], ignore_index=True)\n",
        "\n",
        "print(len(train))"
      ],
      "metadata": {
        "trusted": true,
        "id": "VHu85TFUDiw0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "counts = train.groupby('CategoryID').size()\n",
        "counts = counts.sort_values()\n",
        "counts.head(10)"
      ],
      "metadata": {
        "trusted": true,
        "id": "3P9FCI78Diw0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for category_id in counts.index:\n",
        "    new_rows = []\n",
        "    filtered_queries = train[train['CategoryID'] == category_id]\n",
        "\n",
        "    if counts[category_id] < 50:\n",
        "        for row in filtered_queries.itertuples():\n",
        "\n",
        "            new_rows.append(\n",
        "                {\n",
        "                    'CategoryID': category_id,\n",
        "                    'Query': f'{synonym_replacement(str(row.Query))}'\n",
        "                }\n",
        "            )\n",
        "\n",
        "\n",
        "    elif counts[category_id] < 150:\n",
        "        iters = int((150 - counts[category_id]) / 2)\n",
        "\n",
        "        for row in filtered_queries.itertuples():\n",
        "            new_rows.append(\n",
        "                {\n",
        "                    'CategoryID': category_id,\n",
        "                    'Query': f'{synonym_replacement(str(row.Query))}'\n",
        "                }\n",
        "            )\n",
        "            iters -=1\n",
        "\n",
        "            if iters == 0:\n",
        "                break\n",
        "\n",
        "\n",
        "    if counts[category_id] < 350:\n",
        "        iters = int((350 - counts[category_id]) / 3)\n",
        "\n",
        "        for row in filtered_queries.itertuples():\n",
        "            new_rows.append(\n",
        "                {\n",
        "                    'CategoryID': category_id,\n",
        "                    'Query': f'{synonym_replacement(str(row.Query))}'\n",
        "                }\n",
        "            )\n",
        "            iters -=1\n",
        "\n",
        "            if iters == 0:\n",
        "                break\n",
        "\n",
        "\n",
        "    train = pd.concat([train, pd.DataFrame(new_rows)], ignore_index=True)\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "id": "E8jHqyK6Diw0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train))"
      ],
      "metadata": {
        "trusted": true,
        "id": "0YuTrOiwDiw1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for category_id in counts.index:\n",
        "    new_rows = []\n",
        "    filtered_queries = train[train['CategoryID'] == category_id]\n",
        "    if counts[category_id] < 500:\n",
        "        iters = int((500 - counts[category_id]) / 2)\n",
        "\n",
        "        for row in filtered_queries.itertuples():\n",
        "            query = str(row.Query)\n",
        "            new_rows.append(\n",
        "                {\"CategoryID\": category_id, \"Query\": f\"{shuffle_words(query)}\"}\n",
        "            )\n",
        "            iters -=1\n",
        "\n",
        "            if iters == 0:\n",
        "                break\n",
        "\n",
        "    elif 500 <= counts[category_id] < 800:\n",
        "        iters = int((800 - counts[category_id]) / 4)\n",
        "\n",
        "        for row in filtered_queries.itertuples():\n",
        "            query = str(row.Query)\n",
        "            iters = int((150 - counts[category_id]) / 2)\n",
        "            new_rows.append(\n",
        "                {\"CategoryID\": category_id, \"Query\": f\"{shuffle_words(query)}\"}\n",
        "            )\n",
        "            iters -=1\n",
        "\n",
        "            if iters == 0:\n",
        "                break\n",
        "\n",
        "    train = pd.concat([train, pd.DataFrame(new_rows)], ignore_index=True)\n",
        "\n",
        "print(len(train))"
      ],
      "metadata": {
        "trusted": true,
        "id": "GXOAl3HQDiw1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for category_id in counts.index:\n",
        "    new_rows = []\n",
        "    filtered_queries = train[train['CategoryID'] == category_id]\n",
        "    iters = int(counts[category_id] / 10)\n",
        "\n",
        "    for row in filtered_queries.itertuples():\n",
        "        query = char_augment(row.Query)\n",
        "        new_rows.append(\n",
        "            {\n",
        "                \"CategoryID\": category_id,\n",
        "                \"Query\": f\"{query}\"\n",
        "            }\n",
        "        )\n",
        "        iters -=1\n",
        "\n",
        "        if iters == 0:\n",
        "            break\n",
        "\n",
        "    train = pd.concat([train, pd.DataFrame(new_rows)], ignore_index=True)\n",
        "\n",
        "print(len(train))"
      ],
      "metadata": {
        "trusted": true,
        "id": "njpKj9v0Diw1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,1, figsize=(10, 5))\n",
        "train.groupby('CategoryID').Query.count().sort_values().plot.bar(x='CategoryID', y='Query')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "JvcE2boRDiw1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "trusted": true,
        "id": "yVclUKuuDiw1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    train['Query'].tolist(), train['CategoryID'].tolist(), test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "OnXh4lG5Diw1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "B5sauWh2Diw1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=128)"
      ],
      "metadata": {
        "trusted": true,
        "id": "AQDPdrI2Diw4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class QueryDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "train_dataset = QueryDataset(train_encodings, train_labels)\n",
        "val_dataset = QueryDataset(val_encodings, val_labels)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "wHNA3FthDiw4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "                                                      num_labels=len(train['CategoryID'].unique()),\n",
        "                                                      ignore_mismatched_sizes=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Jw9W2XQdDiw5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW"
      ],
      "metadata": {
        "trusted": true,
        "id": "OdMnvO3YDiw5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Rp_1Dc_DDiw5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "trusted": true,
        "id": "h9A28o3QDiw5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "trusted": true,
        "id": "padkLuCxDiw5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "val_losses = []\n",
        "f1_scores = []\n",
        "precisions = []\n",
        "recalls = []"
      ],
      "metadata": {
        "trusted": true,
        "id": "JB9JH5O_Diw5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "id": "tr-R_eVRDiw5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "trusted": true,
        "id": "78Owwg7hDiw5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-5\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in tqdm(train_loader, desc=\"Training\", leave=False):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        batch = {key: val.to(device) for key, val in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "\n",
        "        loss = loss_fn(outputs.logits, batch[\"labels\"])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    train_losses.append(total_loss / len(train_loader))\n",
        "\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "    val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc=\"Validation\", leave=False):\n",
        "            batch = {key: val.to(device) for key, val in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "\n",
        "            predictions = torch.argmax(outputs.logits, dim=1)\n",
        "            y_true.extend(batch[\"labels\"].cpu().numpy())\n",
        "            y_pred.extend(predictions.cpu().numpy())\n",
        "\n",
        "            val_loss += loss_fn(outputs.logits, batch[\"labels\"]).item()\n",
        "\n",
        "    val_losses.append(val_loss / len(val_loader))\n",
        "\n",
        "    f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
        "    precision = precision_score(y_true, y_pred, average=\"weighted\")\n",
        "    recall = recall_score(y_true, y_pred, average=\"weighted\")\n",
        "\n",
        "    f1_scores.append(f1)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}: Loss = {train_losses[-1]:.4f}, F1 = {f1:.4f}, Precision = {precision:.4f}, Recall = {recall:.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "UxPCFaoWDiw5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, epochs + 1), train_losses, label=\"Train Loss\", marker=\"o\")\n",
        "plt.plot(range(1, epochs + 1), val_losses, label=\"Val Loss\", marker=\"o\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, epochs + 1), f1_scores, label=\"F1-score\", marker=\"s\")\n",
        "plt.plot(range(1, epochs + 1), precisions, label=\"Precision\", marker=\"^\")\n",
        "plt.plot(range(1, epochs + 1), recalls, label=\"Recall\", marker=\"d\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"Evaluation Metrics\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "FlFTDN4BDiw6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_category(query):\n",
        "    model.eval()\n",
        "\n",
        "    inputs = tokenizer(query, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
        "\n",
        "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    predicted_category = torch.argmax(outputs.logits, dim=1).item()\n",
        "\n",
        "    return predicted_category"
      ],
      "metadata": {
        "trusted": true,
        "id": "Q42U34WqDiw6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = test.copy()\n",
        "test_df['CategoryID'] = test_df['Query'].apply(predict_category)\n",
        "del test_df['Query']\n",
        "test_df.head(5)"
      ],
      "metadata": {
        "trusted": true,
        "id": "mPvygepYDiw6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_csv('sub_file_3.csv', index=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "2Dj9FCc-Diw6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp /kaggle/input/kaggle-api-key/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "trusted": true,
        "id": "DvHFAnLoDiw6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c 21vek-query-classification -f sub_file_3.csv -m \"bert_4_epoch\""
      ],
      "metadata": {
        "trusted": true,
        "id": "8Wf4Ef_ADiw6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "vHFy67oqDiw6"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}